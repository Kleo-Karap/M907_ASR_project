{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c32adbd",
   "metadata": {},
   "source": [
    "# Using the pre-trained speech recognition model mozilla Deepspeech to transcribe .wav files (original (lm=0.75), lm=0,lm=1, lm=1.5, lm=2 and noisy (SNR=3,6,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9321cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeech import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import wave\n",
    "import json\n",
    "from IPython.display import Audio\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59fee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepspeech in c:\\users\\kleop\\anaconda3\\envs\\asr\\lib\\site-packages (0.9.3)\n",
      "Requirement already satisfied: numpy>=1.19.4 in c:\\users\\kleop\\anaconda3\\envs\\asr\\lib\\site-packages (from deepspeech) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140df6dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CreateModel failed with 'Failed to initialize memory mapped model.' (0x3000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m lm_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \n\u001b[0;32m      5\u001b[0m lm_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.85\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39menableExternalScorer(lm_file_path)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ASR\\lib\\site-packages\\deepspeech\\__init__.py:38\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     36\u001b[0m status, impl \u001b[38;5;241m=\u001b[39m deepspeech\u001b[38;5;241m.\u001b[39mimpl\u001b[38;5;241m.\u001b[39mCreateModel(model_path)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreateModel failed with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (0x\u001b[39m\u001b[38;5;132;01m{:X}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(deepspeech\u001b[38;5;241m.\u001b[39mimpl\u001b[38;5;241m.\u001b[39mErrorCodeToErrorMessage(status),status))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;241m=\u001b[39m impl\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CreateModel failed with 'Failed to initialize memory mapped model.' (0x3000)"
     ]
    }
   ],
   "source": [
    "model_file_path = 'deepspeech-0.9.3-models.pbmm'\n",
    "lm_file_path = 'deepspeech-0.9.3-models.scorer'\n",
    "beam_width = 100\n",
    "lm_alpha = 0.75\n",
    "lm_beta = 1.85\n",
    "model = Model(model_file_path)\n",
    "model.enableExternalScorer(lm_file_path)\n",
    " \n",
    "#To create the files we adjusted the lm_alpha with the following values: 0, 1, 1.5,2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31f4d3",
   "metadata": {},
   "source": [
    "# Effect of the weight of the language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9364a6",
   "metadata": {},
   "source": [
    "I chose to experiment with the follownig weight on the lm_alpha: \n",
    "\n",
    "lm_alpha=0: Which means we assigned no weight to the language model, disabling its influence during decoding. The model will rely solely on the acoustic model predictions.\n",
    "\n",
    "lm_alpha=1: We assign equal weight to the language model and the acoustic model predictions. This weight implies that we have a high level of confidence  in the language model and want it to have a significant impact on the decoding process.\n",
    "\n",
    "lm_alpha=1.5, lm_alpha=2: The next two weights we experiment with, imply that we overtrust the language model and want to check how biased the results will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8bcf3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
    "model.setBeamWidth(beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4c1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav_file(filename):\n",
    "    with wave.open(filename, 'rb') as w:\n",
    "        rate = w.getframerate()\n",
    "        frames = w.getnframes()\n",
    "        buffer = w.readframes(frames)\n",
    "        print(\"Rate:\", rate)\n",
    "        print(\"Frames:\", frames)\n",
    "        print(\"Buffer Len:\", len(buffer))\n",
    "\n",
    "    return buffer, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3469649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_batch(audio_file):\n",
    "    buffer, rate = read_wav_file(audio_file)\n",
    "    data16 = np.frombuffer(buffer, dtype=np.int16)\n",
    "    return model.stt(data16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e04ce11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate: 16000\n",
      "Frames: 43200\n",
      "Buffer Len: 86400\n",
      "C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/304647\\8842-304647-0001.wav\n",
      "Rate: 16000\n",
      "Frames: 507200\n",
      "Buffer Len: 1014400\n",
      "C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/304647\\8842-304647-0002.wav\n",
      "Rate: 16000\n",
      "Frames: 367360\n",
      "Buffer Len: 734720\n",
      "C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/304647\\8842-304647-0006.wav\n",
      "Rate: 16000\n",
      "Frames: 195120\n",
      "Buffer Len: 390240\n",
      "C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/304647\\8842-304647-0010.wav\n",
      "Rate: 16000\n",
      "Frames: 140080\n",
      "Buffer Len: 280160\n",
      "C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/304647\\8842-304647-0011.wav\n"
     ]
    }
   ],
   "source": [
    "#This one works for the noisy files better\n",
    "output_path =\"C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/transcripts/trans_clean_lm_0.txt\"\n",
    "directory = 'C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/Outputs'\n",
    "for filename in glob.glob(os.path.join(directory, '*.wav')):\n",
    "    t=transcribe_batch(filename)\n",
    "    filename_part = []\n",
    "    filename_part = filename.split('/')\n",
    "    line_transcr = re.sub('.wav','',filename_part[-1])\n",
    "    line_transcr = re.sub('Outputs','',line_transcr)\n",
    "    line_transcr = line_transcr.replace('\\\\', '')\n",
    "    with open(output_path, \"a\") as output_file:\n",
    "            output_file.write(line_transcr+\" \"+t+ \"\\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cec6809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate: 16000\n",
      "Frames: 43200\n",
      "Buffer Len: 86400\n",
      "Rate: 16000\n",
      "Frames: 507200\n",
      "Buffer Len: 1014400\n",
      "Rate: 16000\n",
      "Frames: 367360\n",
      "Buffer Len: 734720\n",
      "Rate: 16000\n",
      "Frames: 195120\n",
      "Buffer Len: 390240\n",
      "Rate: 16000\n",
      "Frames: 140080\n",
      "Buffer Len: 280160\n"
     ]
    }
   ],
   "source": [
    "#This one works for the clean files better\n",
    "output_path =\"C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/transcripts/trans_clean_lm_1.txt\"\n",
    "directory = 'C:/Users/kleop/Documents/repos/Exercises/ASR_assignment/LibriSpeech/dev-clean-2/8842/304647'\n",
    "with open(output_path, \"a\") as output_file:\n",
    "    for filename in glob.glob(os.path.join(directory, '*.wav')):\n",
    "        t = transcribe_batch(filename)\n",
    "        line_transcr = os.path.basename(filename)\n",
    "        line_transcr = os.path.splitext(line_transcr)[0]\n",
    "        line_transcr = line_transcr.replace('\\\\', '')\n",
    "        output_file.write(line_transcr + \" \" + t + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8a047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
